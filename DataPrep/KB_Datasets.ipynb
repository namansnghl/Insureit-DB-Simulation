{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Karan's Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faker in /Users/karanbadlani/anaconda3/lib/python3.11/site-packages (20.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in /Users/karanbadlani/anaconda3/lib/python3.11/site-packages (from faker) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/karanbadlani/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.4->faker) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from faker import Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58082, 74341, 77471, 78932, 94613, 109075, 114971, 144402, 166248, 174408, 176254, 249650, 289060, 293654, 319355, 336850, 345273, 352841, 358893, 365390, 389080, 415216, 492977, 499661, 532909, 538409, 554593, 555849, 591642, 621200, 628418, 632251, 638484, 640537, 719439, 733572, 778711, 830875, 847339, 867938, 871428, 872585, 915790, 930301, 950610, 972654, 974101, 979749, 981115, 987673]\n"
     ]
    }
   ],
   "source": [
    "#Testing Code - Customer_ids\n",
    "df_temp = pd.read_csv('customer.csv')\n",
    "df_temp = df_temp.iloc[:,0]\n",
    "c_id_list = df_temp.values.tolist()\n",
    "print(c_id_list)\n",
    "#df_temp.to_csv('/Users/karanbadlani/Library/Mobile Documents/com~apple~CloudDocs/Desktop/temp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6768, 13041, 33645, 52121, 69259, 73812, 78600, 80340, 85926, 92085, 92900, 95189, 97444]\n"
     ]
    }
   ],
   "source": [
    "#Testing Code - agent_ids\n",
    "df_temp1 = pd.read_csv('agents.csv')\n",
    "df_temp1 = df_temp1.iloc[:,0]\n",
    "agent_id_list = df_temp1.values.tolist()\n",
    "print(agent_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122]\n"
     ]
    }
   ],
   "source": [
    "#Testing Code - auto_policy_ids\n",
    "df_temp2 = pd.read_csv('auto_policy_detail.csv')\n",
    "df_temp2 = df_temp2.iloc[:,0]\n",
    "auto_policy_id_list = df_temp2.values.tolist()\n",
    "print(auto_policy_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111]\n"
     ]
    }
   ],
   "source": [
    "#Testing Code - home_policy_ids\n",
    "df_temp3 = pd.read_csv('home_policy_detail.csv')\n",
    "df_temp3 = df_temp3.iloc[:,0]\n",
    "home_policy_id_list = df_temp3.values.tolist()\n",
    "print(home_policy_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LP001015', 'LP001022', 'LP001031', 'LP001035', 'LP001051', 'LP001054', 'LP001055', 'LP001056', 'LP001059', 'LP001067', 'LP001078', 'LP001082', 'LP001083', 'LP001094', 'LP001096', 'LP001099', 'LP001105', 'LP001107', 'LP001108', 'LP001115', 'LP001121', 'LP001124', 'LP001128', 'LP001135', 'LP001149', 'LP001153', 'LP001163', 'LP001169', 'LP001174', 'LP001176', 'LP001177', 'LP001183', 'LP001185', 'LP001187', 'LP001190', 'LP001203', 'LP001208', 'LP001210', 'LP001211', 'LP001219', 'LP001220', 'LP001221', 'LP001226', 'LP001230', 'LP001231', 'LP001232', 'LP001237', 'LP001242', 'LP001268', 'LP001270', 'LP001284', 'LP001287', 'LP001291', 'LP001298', 'LP001312']\n"
     ]
    }
   ],
   "source": [
    "#Testing Code - loan ids\n",
    "df_temp4 = pd.read_csv('loan.csv')\n",
    "df_temp4 = df_temp4.iloc[:,0]\n",
    "loan_id_list = df_temp4.values.tolist()\n",
    "print(loan_id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working on Policy_Holder Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Holder_id  Customer_id  Home_Policy_id  Auto_Policy_id status_of_policy  \\\n",
      "0           1       492977             106             120           Active   \n",
      "1           2       176254             107             116           Active   \n",
      "2           3       345273             101             122         Inactive   \n",
      "3           4       981115             102             117           Active   \n",
      "4           5       109075             100             116         Inactive   \n",
      "5           6       319355             104             111         Inactive   \n",
      "6           7       492977             101             111           Active   \n",
      "7           8       847339             110             112           Active   \n",
      "8           9       638484             108             114         Inactive   \n",
      "9          10       830875             100             122         Inactive   \n",
      "10         11       352841             110             120         Inactive   \n",
      "11         12       632251             110             116           Active   \n",
      "12         13       640537             108             122         Inactive   \n",
      "13         14       492977             102             121         Inactive   \n",
      "14         15       733572             107             113           Active   \n",
      "15         16       638484             107             114           Active   \n",
      "16         17       336850             111             122           Active   \n",
      "17         18       532909             109             115         Inactive   \n",
      "18         19       336850             106             116           Active   \n",
      "19         20       830875             106             119           Active   \n",
      "20         21        74341             100             122           Active   \n",
      "21         22       872585             104             120           Active   \n",
      "22         23       345273             111             115         Inactive   \n",
      "23         24       719439             100             120           Active   \n",
      "24         25       389080             110             118           Active   \n",
      "25         26       176254             107             119           Active   \n",
      "26         27       950610             105             118           Active   \n",
      "27         28       979749             104             119           Active   \n",
      "28         29       867938             108             120         Inactive   \n",
      "29         30       492977             102             113         Inactive   \n",
      "30         31       319355             100             120           Active   \n",
      "31         32       365390             106             121           Active   \n",
      "32         33       109075             108             114           Active   \n",
      "33         34       871428             105             114           Active   \n",
      "34         35       555849             103             112         Inactive   \n",
      "35         36       319355             103             119           Active   \n",
      "36         37       638484             110             116         Inactive   \n",
      "37         38        77471             105             112         Inactive   \n",
      "38         39       554593             103             121           Active   \n",
      "39         40       719439             100             121         Inactive   \n",
      "40         41       847339             101             111           Active   \n",
      "41         42       144402             101             113         Inactive   \n",
      "42         43       719439             106             122         Inactive   \n",
      "43         44       345273             108             115         Inactive   \n",
      "44         45       365390             111             115           Active   \n",
      "45         46       336850             102             122         Inactive   \n",
      "46         47       972654             104             113         Inactive   \n",
      "47         48        58082             110             111           Active   \n",
      "48         49       166248             106             113         Inactive   \n",
      "49         50       847339             109             119         Inactive   \n",
      "\n",
      "    StartDate ExpiryDate  RenewDate at_risk_flag  Agent_id  \n",
      "0  2022-06-22 2022-10-29 2023-05-27          Yes     13041  \n",
      "1  2022-02-19 2022-10-29 2023-02-09          Yes      6768  \n",
      "2  2022-06-26 2022-08-18 2023-04-27          Yes     85926  \n",
      "3  2022-06-16 2022-07-25 2023-02-06           No     69259  \n",
      "4  2022-03-14 2022-08-13 2023-03-13          Yes     85926  \n",
      "5  2022-06-05 2022-11-23 2023-04-28           No     52121  \n",
      "6  2022-02-04 2022-08-03 2023-04-05          Yes     92900  \n",
      "7  2022-04-06 2022-07-15 2023-04-11          Yes     73812  \n",
      "8  2022-03-15 2022-11-06 2023-06-09          Yes     52121  \n",
      "9  2022-01-10 2022-09-01 2023-03-17          Yes     92900  \n",
      "10 2022-03-23 2022-10-18 2023-01-01           No     80340  \n",
      "11 2022-01-07 2022-09-22 2023-04-12           No     13041  \n",
      "12 2022-06-21 2022-07-05 2023-03-07           No     33645  \n",
      "13 2022-02-12 2022-09-09 2023-05-01          Yes     92085  \n",
      "14 2022-03-18 2022-12-24 2023-05-14          Yes     78600  \n",
      "15 2022-01-11 2022-09-25 2023-06-12          Yes     78600  \n",
      "16 2022-01-23 2022-12-11 2023-01-25          Yes     13041  \n",
      "17 2022-06-24 2022-11-20 2023-05-07          Yes     85926  \n",
      "18 2022-04-15 2022-07-29 2023-04-21          Yes     52121  \n",
      "19 2022-01-11 2022-08-25 2023-01-03           No     92085  \n",
      "20 2022-04-24 2022-09-12 2023-02-09           No     92085  \n",
      "21 2022-06-01 2022-07-02 2023-06-21           No     92900  \n",
      "22 2022-02-18 2022-11-05 2023-02-06          Yes     78600  \n",
      "23 2022-06-20 2022-12-27 2023-03-04          Yes     97444  \n",
      "24 2022-06-23 2022-08-20 2023-01-30           No     33645  \n",
      "25 2022-04-13 2022-08-09 2023-06-08           No     92085  \n",
      "26 2022-01-21 2022-10-21 2023-06-21           No     85926  \n",
      "27 2022-05-12 2022-12-24 2023-05-26           No     92085  \n",
      "28 2022-01-21 2022-08-10 2023-05-05           No     69259  \n",
      "29 2022-06-11 2022-10-07 2023-02-20          Yes     80340  \n",
      "30 2022-03-26 2022-08-03 2023-06-04           No      6768  \n",
      "31 2022-03-20 2022-07-02 2023-01-28          Yes     95189  \n",
      "32 2022-02-10 2022-09-18 2023-03-30           No     73812  \n",
      "33 2022-05-26 2022-09-30 2023-01-18           No     92085  \n",
      "34 2022-01-16 2022-12-30 2023-01-12          Yes     92085  \n",
      "35 2022-05-13 2022-10-26 2023-04-23           No     33645  \n",
      "36 2022-06-30 2022-12-19 2023-02-15          Yes     73812  \n",
      "37 2022-01-12 2022-12-07 2023-03-16          Yes     92900  \n",
      "38 2022-05-02 2022-10-27 2023-04-18          Yes     33645  \n",
      "39 2022-02-04 2022-10-15 2023-02-18           No     85926  \n",
      "40 2022-06-06 2022-12-01 2023-01-05           No     13041  \n",
      "41 2022-01-15 2022-07-12 2023-05-17          Yes     73812  \n",
      "42 2022-06-16 2022-07-13 2023-06-22           No     73812  \n",
      "43 2022-04-04 2022-09-11 2023-06-19          Yes     80340  \n",
      "44 2022-03-11 2022-12-25 2023-03-06           No     69259  \n",
      "45 2022-02-16 2022-08-25 2023-02-20          Yes     95189  \n",
      "46 2022-05-07 2022-07-18 2023-04-06          Yes      6768  \n",
      "47 2022-01-18 2022-09-02 2023-01-18          Yes     95189  \n",
      "48 2022-02-16 2022-08-07 2023-06-21          Yes     33645  \n",
      "49 2022-03-02 2022-07-29 2023-02-05           No     80340  \n"
     ]
    }
   ],
   "source": [
    "# Function to generate random dates within a given range\n",
    "def random_dates(start_date, end_date, n=10):\n",
    "    date_range = [start_date + timedelta(days=random.randint(0, (end_date - start_date).days)) for _ in range(n)]\n",
    "    return date_range\n",
    "\n",
    "# Sample data for Policy_Holder\n",
    "customer_ids = c_id_list\n",
    "\n",
    "auto_policy_ids = auto_policy_id_list\n",
    "home_policy_ids = home_policy_id_list\n",
    "agent_ids = agent_id_list\n",
    "\n",
    "# Create a DataFrame for Policy_Holder\n",
    "# home_policy_ids = random.choices(home_policy_ids, k=50)\n",
    "# auto_policy_ids = random.choices(auto_policy_ids, k=50)\n",
    "# policy_ids = [auto_policy_ids[i] if auto_policy_ids[i] != 0 else home_policy_ids[i] for i in range(50)]\n",
    "\n",
    "data = {\n",
    "    'Holder_id': list(range(1, 51)),\n",
    "    'Customer_id': random.choices(customer_ids, k=50),\n",
    "    \n",
    "    'Home_Policy_id' : random.choices(home_policy_ids, k=50),\n",
    "   \n",
    "    'Auto_Policy_id': random.choices(auto_policy_ids, k=50),\n",
    "    #'Policy_type': ['Auto' if auto_policy_ids[i] != 0 else 'Home' if home_policy_ids[i] != 0 else 'Both' if auto_policy_ids[i] != 0 and home_policy_ids[i] != 0 else None for i in range(50)],\n",
    "    'status_of_policy': random.choices(['Active', 'Inactive'], k=50),\n",
    "    'StartDate': random_dates(datetime(2022, 1, 1), datetime(2022, 6, 30), n=50),\n",
    "    'ExpiryDate': random_dates(datetime(2022, 7, 1), datetime(2022, 12, 31), n=50),\n",
    "    'RenewDate': random_dates(datetime(2023, 1, 1), datetime(2023, 6, 30), n=50),\n",
    "    'at_risk_flag': random.choices(['Yes', 'No'], k=50),\n",
    "    'Agent_id': random.choices(agent_ids, k=50)\n",
    "}\n",
    "\n",
    "policy_holder_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(policy_holder_df)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "policy_holder_df.to_csv('policy_holder.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT INTO Policy_Holder VALUES (1,492977,106,120,'Active','2022-06-22 00:00:00','2022-10-29 00:00:00', '2023-05-27 00:00:00','Yes',13041);\n",
      "INSERT INTO Policy_Holder VALUES (2,176254,107,116,'Active','2022-02-19 00:00:00','2022-10-29 00:00:00', '2023-02-09 00:00:00','Yes',6768);\n",
      "INSERT INTO Policy_Holder VALUES (3,345273,101,122,'Inactive','2022-06-26 00:00:00','2022-08-18 00:00:00', '2023-04-27 00:00:00','Yes',85926);\n",
      "INSERT INTO Policy_Holder VALUES (4,981115,102,117,'Active','2022-06-16 00:00:00','2022-07-25 00:00:00', '2023-02-06 00:00:00','No',69259);\n",
      "INSERT INTO Policy_Holder VALUES (5,109075,100,116,'Inactive','2022-03-14 00:00:00','2022-08-13 00:00:00', '2023-03-13 00:00:00','Yes',85926);\n",
      "INSERT INTO Policy_Holder VALUES (6,319355,104,111,'Inactive','2022-06-05 00:00:00','2022-11-23 00:00:00', '2023-04-28 00:00:00','No',52121);\n",
      "INSERT INTO Policy_Holder VALUES (7,492977,101,111,'Active','2022-02-04 00:00:00','2022-08-03 00:00:00', '2023-04-05 00:00:00','Yes',92900);\n",
      "INSERT INTO Policy_Holder VALUES (8,847339,110,112,'Active','2022-04-06 00:00:00','2022-07-15 00:00:00', '2023-04-11 00:00:00','Yes',73812);\n",
      "INSERT INTO Policy_Holder VALUES (9,638484,108,114,'Inactive','2022-03-15 00:00:00','2022-11-06 00:00:00', '2023-06-09 00:00:00','Yes',52121);\n",
      "INSERT INTO Policy_Holder VALUES (10,830875,100,122,'Inactive','2022-01-10 00:00:00','2022-09-01 00:00:00', '2023-03-17 00:00:00','Yes',92900);\n",
      "INSERT INTO Policy_Holder VALUES (11,352841,110,120,'Inactive','2022-03-23 00:00:00','2022-10-18 00:00:00', '2023-01-01 00:00:00','No',80340);\n",
      "INSERT INTO Policy_Holder VALUES (12,632251,110,116,'Active','2022-01-07 00:00:00','2022-09-22 00:00:00', '2023-04-12 00:00:00','No',13041);\n",
      "INSERT INTO Policy_Holder VALUES (13,640537,108,122,'Inactive','2022-06-21 00:00:00','2022-07-05 00:00:00', '2023-03-07 00:00:00','No',33645);\n",
      "INSERT INTO Policy_Holder VALUES (14,492977,102,121,'Inactive','2022-02-12 00:00:00','2022-09-09 00:00:00', '2023-05-01 00:00:00','Yes',92085);\n",
      "INSERT INTO Policy_Holder VALUES (15,733572,107,113,'Active','2022-03-18 00:00:00','2022-12-24 00:00:00', '2023-05-14 00:00:00','Yes',78600);\n",
      "INSERT INTO Policy_Holder VALUES (16,638484,107,114,'Active','2022-01-11 00:00:00','2022-09-25 00:00:00', '2023-06-12 00:00:00','Yes',78600);\n",
      "INSERT INTO Policy_Holder VALUES (17,336850,111,122,'Active','2022-01-23 00:00:00','2022-12-11 00:00:00', '2023-01-25 00:00:00','Yes',13041);\n",
      "INSERT INTO Policy_Holder VALUES (18,532909,109,115,'Inactive','2022-06-24 00:00:00','2022-11-20 00:00:00', '2023-05-07 00:00:00','Yes',85926);\n",
      "INSERT INTO Policy_Holder VALUES (19,336850,106,116,'Active','2022-04-15 00:00:00','2022-07-29 00:00:00', '2023-04-21 00:00:00','Yes',52121);\n",
      "INSERT INTO Policy_Holder VALUES (20,830875,106,119,'Active','2022-01-11 00:00:00','2022-08-25 00:00:00', '2023-01-03 00:00:00','No',92085);\n",
      "INSERT INTO Policy_Holder VALUES (21,74341,100,122,'Active','2022-04-24 00:00:00','2022-09-12 00:00:00', '2023-02-09 00:00:00','No',92085);\n",
      "INSERT INTO Policy_Holder VALUES (22,872585,104,120,'Active','2022-06-01 00:00:00','2022-07-02 00:00:00', '2023-06-21 00:00:00','No',92900);\n",
      "INSERT INTO Policy_Holder VALUES (23,345273,111,115,'Inactive','2022-02-18 00:00:00','2022-11-05 00:00:00', '2023-02-06 00:00:00','Yes',78600);\n",
      "INSERT INTO Policy_Holder VALUES (24,719439,100,120,'Active','2022-06-20 00:00:00','2022-12-27 00:00:00', '2023-03-04 00:00:00','Yes',97444);\n",
      "INSERT INTO Policy_Holder VALUES (25,389080,110,118,'Active','2022-06-23 00:00:00','2022-08-20 00:00:00', '2023-01-30 00:00:00','No',33645);\n",
      "INSERT INTO Policy_Holder VALUES (26,176254,107,119,'Active','2022-04-13 00:00:00','2022-08-09 00:00:00', '2023-06-08 00:00:00','No',92085);\n",
      "INSERT INTO Policy_Holder VALUES (27,950610,105,118,'Active','2022-01-21 00:00:00','2022-10-21 00:00:00', '2023-06-21 00:00:00','No',85926);\n",
      "INSERT INTO Policy_Holder VALUES (28,979749,104,119,'Active','2022-05-12 00:00:00','2022-12-24 00:00:00', '2023-05-26 00:00:00','No',92085);\n",
      "INSERT INTO Policy_Holder VALUES (29,867938,108,120,'Inactive','2022-01-21 00:00:00','2022-08-10 00:00:00', '2023-05-05 00:00:00','No',69259);\n",
      "INSERT INTO Policy_Holder VALUES (30,492977,102,113,'Inactive','2022-06-11 00:00:00','2022-10-07 00:00:00', '2023-02-20 00:00:00','Yes',80340);\n",
      "INSERT INTO Policy_Holder VALUES (31,319355,100,120,'Active','2022-03-26 00:00:00','2022-08-03 00:00:00', '2023-06-04 00:00:00','No',6768);\n",
      "INSERT INTO Policy_Holder VALUES (32,365390,106,121,'Active','2022-03-20 00:00:00','2022-07-02 00:00:00', '2023-01-28 00:00:00','Yes',95189);\n",
      "INSERT INTO Policy_Holder VALUES (33,109075,108,114,'Active','2022-02-10 00:00:00','2022-09-18 00:00:00', '2023-03-30 00:00:00','No',73812);\n",
      "INSERT INTO Policy_Holder VALUES (34,871428,105,114,'Active','2022-05-26 00:00:00','2022-09-30 00:00:00', '2023-01-18 00:00:00','No',92085);\n",
      "INSERT INTO Policy_Holder VALUES (35,555849,103,112,'Inactive','2022-01-16 00:00:00','2022-12-30 00:00:00', '2023-01-12 00:00:00','Yes',92085);\n",
      "INSERT INTO Policy_Holder VALUES (36,319355,103,119,'Active','2022-05-13 00:00:00','2022-10-26 00:00:00', '2023-04-23 00:00:00','No',33645);\n",
      "INSERT INTO Policy_Holder VALUES (37,638484,110,116,'Inactive','2022-06-30 00:00:00','2022-12-19 00:00:00', '2023-02-15 00:00:00','Yes',73812);\n",
      "INSERT INTO Policy_Holder VALUES (38,77471,105,112,'Inactive','2022-01-12 00:00:00','2022-12-07 00:00:00', '2023-03-16 00:00:00','Yes',92900);\n",
      "INSERT INTO Policy_Holder VALUES (39,554593,103,121,'Active','2022-05-02 00:00:00','2022-10-27 00:00:00', '2023-04-18 00:00:00','Yes',33645);\n",
      "INSERT INTO Policy_Holder VALUES (40,719439,100,121,'Inactive','2022-02-04 00:00:00','2022-10-15 00:00:00', '2023-02-18 00:00:00','No',85926);\n",
      "INSERT INTO Policy_Holder VALUES (41,847339,101,111,'Active','2022-06-06 00:00:00','2022-12-01 00:00:00', '2023-01-05 00:00:00','No',13041);\n",
      "INSERT INTO Policy_Holder VALUES (42,144402,101,113,'Inactive','2022-01-15 00:00:00','2022-07-12 00:00:00', '2023-05-17 00:00:00','Yes',73812);\n",
      "INSERT INTO Policy_Holder VALUES (43,719439,106,122,'Inactive','2022-06-16 00:00:00','2022-07-13 00:00:00', '2023-06-22 00:00:00','No',73812);\n",
      "INSERT INTO Policy_Holder VALUES (44,345273,108,115,'Inactive','2022-04-04 00:00:00','2022-09-11 00:00:00', '2023-06-19 00:00:00','Yes',80340);\n",
      "INSERT INTO Policy_Holder VALUES (45,365390,111,115,'Active','2022-03-11 00:00:00','2022-12-25 00:00:00', '2023-03-06 00:00:00','No',69259);\n",
      "INSERT INTO Policy_Holder VALUES (46,336850,102,122,'Inactive','2022-02-16 00:00:00','2022-08-25 00:00:00', '2023-02-20 00:00:00','Yes',95189);\n",
      "INSERT INTO Policy_Holder VALUES (47,972654,104,113,'Inactive','2022-05-07 00:00:00','2022-07-18 00:00:00', '2023-04-06 00:00:00','Yes',6768);\n",
      "INSERT INTO Policy_Holder VALUES (48,58082,110,111,'Active','2022-01-18 00:00:00','2022-09-02 00:00:00', '2023-01-18 00:00:00','Yes',95189);\n",
      "INSERT INTO Policy_Holder VALUES (49,166248,106,113,'Inactive','2022-02-16 00:00:00','2022-08-07 00:00:00', '2023-06-21 00:00:00','Yes',33645);\n",
      "INSERT INTO Policy_Holder VALUES (50,847339,109,119,'Inactive','2022-03-02 00:00:00','2022-07-29 00:00:00', '2023-02-05 00:00:00','No',80340);\n"
     ]
    }
   ],
   "source": [
    "#Inset Query Generation for Policy_Holder\n",
    "#creating INSERT SQL file for Policy_holder table\n",
    "for Holder_id, Customer_id, Home_Policy_id, Auto_Policy_id, status_of_policy, Start_Date, ExpiryDate, RenewDate, at_risk_flag, Agent_id in policy_holder_df.values.tolist():\n",
    "    print(\"INSERT INTO Policy_Holder VALUES ({},{},{},{},'{}','{}','{}', '{}','{}',{});\".format(Holder_id, Customer_id, Home_Policy_id, Auto_Policy_id, status_of_policy, Start_Date, ExpiryDate, RenewDate, at_risk_flag, Agent_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working on Report_Details Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Generate data for Report_Details\n",
    "data = {\n",
    "    'Report_id': list(range(1, 31)),\n",
    "    'Date': [fake.date_between(start_date='-365d', end_date='today') for _ in range(30)],\n",
    "    'Damage_amount': [random.randint(100, 10000) for _ in range(30)]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "report_details_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(report_details_df)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "report_details_df.to_csv('report_details_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_details_df = pd.read_csv('report_details_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT INTO Report_Details VALUES (1,'2023-04-11',4900);\n",
      "INSERT INTO Report_Details VALUES (2,'2023-10-12',4034);\n",
      "INSERT INTO Report_Details VALUES (3,'2023-07-30',4697);\n",
      "INSERT INTO Report_Details VALUES (4,'2023-06-03',3866);\n",
      "INSERT INTO Report_Details VALUES (5,'2022-11-12',8843);\n",
      "INSERT INTO Report_Details VALUES (6,'2023-03-30',5203);\n",
      "INSERT INTO Report_Details VALUES (7,'2023-06-20',3597);\n",
      "INSERT INTO Report_Details VALUES (8,'2023-09-06',7932);\n",
      "INSERT INTO Report_Details VALUES (9,'2023-03-07',9240);\n",
      "INSERT INTO Report_Details VALUES (10,'2023-03-12',8678);\n",
      "INSERT INTO Report_Details VALUES (11,'2023-04-02',2970);\n",
      "INSERT INTO Report_Details VALUES (12,'2023-08-18',5651);\n",
      "INSERT INTO Report_Details VALUES (13,'2023-01-10',2433);\n",
      "INSERT INTO Report_Details VALUES (14,'2023-02-01',7481);\n",
      "INSERT INTO Report_Details VALUES (15,'2023-10-13',9606);\n",
      "INSERT INTO Report_Details VALUES (16,'2023-01-02',4016);\n",
      "INSERT INTO Report_Details VALUES (17,'2023-03-25',3825);\n",
      "INSERT INTO Report_Details VALUES (18,'2022-12-15',5752);\n",
      "INSERT INTO Report_Details VALUES (19,'2023-05-10',1536);\n",
      "INSERT INTO Report_Details VALUES (20,'2023-09-18',2185);\n",
      "INSERT INTO Report_Details VALUES (21,'2023-08-19',4878);\n",
      "INSERT INTO Report_Details VALUES (22,'2023-09-09',7132);\n",
      "INSERT INTO Report_Details VALUES (23,'2023-09-29',7753);\n",
      "INSERT INTO Report_Details VALUES (24,'2023-06-07',9326);\n",
      "INSERT INTO Report_Details VALUES (25,'2022-12-26',5812);\n",
      "INSERT INTO Report_Details VALUES (26,'2023-01-18',7734);\n",
      "INSERT INTO Report_Details VALUES (27,'2023-08-04',6483);\n",
      "INSERT INTO Report_Details VALUES (28,'2023-08-26',3024);\n",
      "INSERT INTO Report_Details VALUES (29,'2023-06-27',2968);\n",
      "INSERT INTO Report_Details VALUES (30,'2023-03-08',8971);\n"
     ]
    }
   ],
   "source": [
    "#creating INSERT SQL file for Report_Details table\n",
    "for Report_id, Date, Damage_amount  in report_details_df.values.tolist():\n",
    "    print(\"INSERT INTO Report_Details VALUES ({},'{}',{});\".format(Report_id, Date, Damage_amount))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working on Vehicle_Details Table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to 'vehicle_details.csv'\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "holder_ids = list(range(1, 51))\n",
    "loan_ids = loan_id_list\n",
    "manufacturers = ['Honda', 'BMW','Toyota','Tata', 'Audi', 'Mercedes', 'Mazda', 'Lamborghini', 'Mustang', 'Kia', 'Maruti', 'Lincoln', 'Ford','Bentley']\n",
    "damage_levels = ['No damage', 'Some damage', 'High damage']\n",
    "owner_types = [1, 2, 3]\n",
    "age_categories = [1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "# Generating data for the table\n",
    "data = []\n",
    "for asset_id in range(1, 101):  # Assuming 100 records\n",
    "    name = f'Vehicle_{asset_id}'\n",
    "    manufacturer = random.choice(manufacturers)\n",
    "    age = random.choice(age_categories)\n",
    "    damage = random.choice(damage_levels)\n",
    "    owner_number = random.choice(owner_types)\n",
    "    holder_id = random.choice(holder_ids)\n",
    "    loan_id = random.choice(loan_ids)\n",
    "\n",
    "    # Derive Model_type logic from vehicle_type\n",
    "    if random.choice([True, False]):\n",
    "        model_type = 'Two Wheeler'\n",
    "    else:\n",
    "        model_type = 'Four Wheeler'\n",
    "\n",
    "    data.append((asset_id, model_type, name, manufacturer, age, damage, owner_number, holder_id, loan_id))\n",
    "\n",
    "# Create a DataFrame\n",
    "columns = ['Asset_id', 'Model_type', 'Name', 'Manufacturer', 'Age', 'Damage', 'Owner_number', 'Holder_id', 'LoanId']\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Save to CSV file\n",
    "df.to_csv('vehicle_details.csv', index=False)\n",
    "\n",
    "print(\"Data saved to 'vehicle_details.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT INTO Vehicle_Details VALUES (1,'Two Wheeler','Vehicle_1','Honda',7,'No damage',2,42,'LP001135');\n",
      "INSERT INTO Vehicle_Details VALUES (2,'Two Wheeler','Vehicle_2','Lincoln',7,'Some damage',2,37,'LP001177');\n",
      "INSERT INTO Vehicle_Details VALUES (3,'Two Wheeler','Vehicle_3','Lincoln',5,'No damage',2,41,'LP001219');\n",
      "INSERT INTO Vehicle_Details VALUES (4,'Two Wheeler','Vehicle_4','Lamborghini',4,'Some damage',1,34,'LP001059');\n",
      "INSERT INTO Vehicle_Details VALUES (5,'Four Wheeler','Vehicle_5','Lincoln',7,'Some damage',2,38,'LP001094');\n",
      "INSERT INTO Vehicle_Details VALUES (6,'Two Wheeler','Vehicle_6','Maruti',2,'No damage',3,28,'LP001135');\n",
      "INSERT INTO Vehicle_Details VALUES (7,'Two Wheeler','Vehicle_7','Toyota',2,'High damage',1,34,'LP001082');\n",
      "INSERT INTO Vehicle_Details VALUES (8,'Four Wheeler','Vehicle_8','Maruti',1,'High damage',1,12,'LP001121');\n",
      "INSERT INTO Vehicle_Details VALUES (9,'Two Wheeler','Vehicle_9','Kia',1,'High damage',2,42,'LP001231');\n",
      "INSERT INTO Vehicle_Details VALUES (10,'Two Wheeler','Vehicle_10','Lincoln',3,'High damage',3,26,'LP001211');\n",
      "INSERT INTO Vehicle_Details VALUES (11,'Four Wheeler','Vehicle_11','Mazda',6,'High damage',2,28,'LP001211');\n",
      "INSERT INTO Vehicle_Details VALUES (12,'Four Wheeler','Vehicle_12','Audi',5,'High damage',1,16,'LP001035');\n",
      "INSERT INTO Vehicle_Details VALUES (13,'Four Wheeler','Vehicle_13','Kia',7,'Some damage',2,33,'LP001312');\n",
      "INSERT INTO Vehicle_Details VALUES (14,'Four Wheeler','Vehicle_14','Toyota',6,'Some damage',1,6,'LP001135');\n",
      "INSERT INTO Vehicle_Details VALUES (15,'Two Wheeler','Vehicle_15','Bentley',3,'Some damage',2,48,'LP001220');\n",
      "INSERT INTO Vehicle_Details VALUES (16,'Four Wheeler','Vehicle_16','Toyota',2,'No damage',1,25,'LP001121');\n",
      "INSERT INTO Vehicle_Details VALUES (17,'Two Wheeler','Vehicle_17','BMW',4,'Some damage',2,39,'LP001190');\n",
      "INSERT INTO Vehicle_Details VALUES (18,'Four Wheeler','Vehicle_18','Lamborghini',6,'No damage',2,28,'LP001291');\n",
      "INSERT INTO Vehicle_Details VALUES (19,'Two Wheeler','Vehicle_19','Mercedes',7,'No damage',1,39,'LP001121');\n",
      "INSERT INTO Vehicle_Details VALUES (20,'Four Wheeler','Vehicle_20','BMW',2,'High damage',3,13,'LP001221');\n",
      "INSERT INTO Vehicle_Details VALUES (21,'Two Wheeler','Vehicle_21','Kia',3,'Some damage',1,15,'LP001015');\n",
      "INSERT INTO Vehicle_Details VALUES (22,'Two Wheeler','Vehicle_22','Lamborghini',4,'High damage',1,16,'LP001219');\n",
      "INSERT INTO Vehicle_Details VALUES (23,'Four Wheeler','Vehicle_23','Tata',4,'High damage',1,41,'LP001078');\n",
      "INSERT INTO Vehicle_Details VALUES (24,'Two Wheeler','Vehicle_24','Ford',6,'High damage',2,15,'LP001268');\n",
      "INSERT INTO Vehicle_Details VALUES (25,'Two Wheeler','Vehicle_25','Maruti',2,'High damage',3,12,'LP001022');\n",
      "INSERT INTO Vehicle_Details VALUES (26,'Two Wheeler','Vehicle_26','Mercedes',1,'High damage',2,32,'LP001054');\n",
      "INSERT INTO Vehicle_Details VALUES (27,'Four Wheeler','Vehicle_27','Lamborghini',1,'No damage',3,28,'LP001291');\n",
      "INSERT INTO Vehicle_Details VALUES (28,'Two Wheeler','Vehicle_28','Mercedes',7,'High damage',1,13,'LP001035');\n",
      "INSERT INTO Vehicle_Details VALUES (29,'Two Wheeler','Vehicle_29','Kia',1,'High damage',1,33,'LP001174');\n",
      "INSERT INTO Vehicle_Details VALUES (30,'Two Wheeler','Vehicle_30','Kia',7,'Some damage',2,2,'LP001268');\n",
      "INSERT INTO Vehicle_Details VALUES (31,'Two Wheeler','Vehicle_31','Mercedes',4,'Some damage',2,36,'LP001270');\n",
      "INSERT INTO Vehicle_Details VALUES (32,'Two Wheeler','Vehicle_32','Lamborghini',3,'High damage',2,26,'LP001208');\n",
      "INSERT INTO Vehicle_Details VALUES (33,'Four Wheeler','Vehicle_33','Toyota',6,'High damage',2,19,'LP001128');\n",
      "INSERT INTO Vehicle_Details VALUES (34,'Two Wheeler','Vehicle_34','Honda',3,'No damage',2,42,'LP001231');\n",
      "INSERT INTO Vehicle_Details VALUES (35,'Four Wheeler','Vehicle_35','Lamborghini',2,'High damage',1,47,'LP001190');\n",
      "INSERT INTO Vehicle_Details VALUES (36,'Four Wheeler','Vehicle_36','Maruti',5,'Some damage',3,29,'LP001242');\n",
      "INSERT INTO Vehicle_Details VALUES (37,'Four Wheeler','Vehicle_37','Mustang',4,'Some damage',3,38,'LP001211');\n",
      "INSERT INTO Vehicle_Details VALUES (38,'Four Wheeler','Vehicle_38','Bentley',4,'No damage',1,6,'LP001220');\n",
      "INSERT INTO Vehicle_Details VALUES (39,'Four Wheeler','Vehicle_39','Toyota',6,'High damage',2,38,'LP001078');\n",
      "INSERT INTO Vehicle_Details VALUES (40,'Two Wheeler','Vehicle_40','Toyota',4,'High damage',1,41,'LP001291');\n",
      "INSERT INTO Vehicle_Details VALUES (41,'Four Wheeler','Vehicle_41','Lincoln',1,'No damage',3,15,'LP001287');\n",
      "INSERT INTO Vehicle_Details VALUES (42,'Four Wheeler','Vehicle_42','BMW',2,'High damage',2,16,'LP001284');\n",
      "INSERT INTO Vehicle_Details VALUES (43,'Two Wheeler','Vehicle_43','Honda',3,'Some damage',1,11,'LP001287');\n",
      "INSERT INTO Vehicle_Details VALUES (44,'Four Wheeler','Vehicle_44','Maruti',7,'No damage',1,36,'LP001232');\n",
      "INSERT INTO Vehicle_Details VALUES (45,'Four Wheeler','Vehicle_45','Ford',4,'No damage',1,22,'LP001035');\n",
      "INSERT INTO Vehicle_Details VALUES (46,'Two Wheeler','Vehicle_46','Mustang',2,'No damage',3,35,'LP001015');\n",
      "INSERT INTO Vehicle_Details VALUES (47,'Two Wheeler','Vehicle_47','Kia',7,'Some damage',1,45,'LP001232');\n",
      "INSERT INTO Vehicle_Details VALUES (48,'Two Wheeler','Vehicle_48','Mustang',7,'No damage',3,45,'LP001208');\n",
      "INSERT INTO Vehicle_Details VALUES (49,'Four Wheeler','Vehicle_49','Toyota',2,'No damage',1,46,'LP001230');\n",
      "INSERT INTO Vehicle_Details VALUES (50,'Two Wheeler','Vehicle_50','Audi',4,'Some damage',2,8,'LP001232');\n",
      "INSERT INTO Vehicle_Details VALUES (51,'Four Wheeler','Vehicle_51','Mustang',7,'High damage',1,9,'LP001287');\n",
      "INSERT INTO Vehicle_Details VALUES (52,'Two Wheeler','Vehicle_52','Lincoln',7,'Some damage',2,26,'LP001208');\n",
      "INSERT INTO Vehicle_Details VALUES (53,'Four Wheeler','Vehicle_53','Ford',4,'High damage',2,4,'LP001083');\n",
      "INSERT INTO Vehicle_Details VALUES (54,'Two Wheeler','Vehicle_54','Lamborghini',2,'No damage',2,15,'LP001219');\n",
      "INSERT INTO Vehicle_Details VALUES (55,'Two Wheeler','Vehicle_55','Honda',2,'Some damage',2,44,'LP001177');\n",
      "INSERT INTO Vehicle_Details VALUES (56,'Two Wheeler','Vehicle_56','Kia',2,'No damage',2,29,'LP001176');\n",
      "INSERT INTO Vehicle_Details VALUES (57,'Four Wheeler','Vehicle_57','Audi',2,'No damage',3,49,'LP001149');\n",
      "INSERT INTO Vehicle_Details VALUES (58,'Two Wheeler','Vehicle_58','Kia',3,'No damage',2,9,'LP001287');\n",
      "INSERT INTO Vehicle_Details VALUES (59,'Two Wheeler','Vehicle_59','Honda',2,'No damage',1,37,'LP001237');\n",
      "INSERT INTO Vehicle_Details VALUES (60,'Four Wheeler','Vehicle_60','Audi',1,'High damage',1,26,'LP001211');\n",
      "INSERT INTO Vehicle_Details VALUES (61,'Two Wheeler','Vehicle_61','Mustang',2,'High damage',3,40,'LP001128');\n",
      "INSERT INTO Vehicle_Details VALUES (62,'Four Wheeler','Vehicle_62','Lamborghini',4,'No damage',2,26,'LP001230');\n",
      "INSERT INTO Vehicle_Details VALUES (63,'Four Wheeler','Vehicle_63','Audi',4,'No damage',2,19,'LP001219');\n",
      "INSERT INTO Vehicle_Details VALUES (64,'Four Wheeler','Vehicle_64','Kia',4,'High damage',1,36,'LP001108');\n",
      "INSERT INTO Vehicle_Details VALUES (65,'Four Wheeler','Vehicle_65','Mustang',2,'High damage',1,9,'LP001108');\n",
      "INSERT INTO Vehicle_Details VALUES (66,'Two Wheeler','Vehicle_66','Bentley',2,'High damage',2,19,'LP001124');\n",
      "INSERT INTO Vehicle_Details VALUES (67,'Four Wheeler','Vehicle_67','Mustang',4,'High damage',3,6,'LP001219');\n",
      "INSERT INTO Vehicle_Details VALUES (68,'Four Wheeler','Vehicle_68','Lamborghini',6,'No damage',2,45,'LP001284');\n",
      "INSERT INTO Vehicle_Details VALUES (69,'Four Wheeler','Vehicle_69','Maruti',2,'Some damage',2,48,'LP001056');\n",
      "INSERT INTO Vehicle_Details VALUES (70,'Four Wheeler','Vehicle_70','Tata',7,'No damage',1,13,'LP001177');\n",
      "INSERT INTO Vehicle_Details VALUES (71,'Four Wheeler','Vehicle_71','Toyota',7,'No damage',1,27,'LP001232');\n",
      "INSERT INTO Vehicle_Details VALUES (72,'Four Wheeler','Vehicle_72','Mercedes',5,'Some damage',2,16,'LP001082');\n",
      "INSERT INTO Vehicle_Details VALUES (73,'Two Wheeler','Vehicle_73','Toyota',5,'High damage',2,47,'LP001203');\n",
      "INSERT INTO Vehicle_Details VALUES (74,'Four Wheeler','Vehicle_74','Toyota',6,'High damage',3,5,'LP001153');\n",
      "INSERT INTO Vehicle_Details VALUES (75,'Two Wheeler','Vehicle_75','Lincoln',4,'High damage',3,12,'LP001051');\n",
      "INSERT INTO Vehicle_Details VALUES (76,'Four Wheeler','Vehicle_76','Mustang',5,'High damage',3,32,'LP001124');\n",
      "INSERT INTO Vehicle_Details VALUES (77,'Four Wheeler','Vehicle_77','Ford',6,'No damage',2,26,'LP001094');\n",
      "INSERT INTO Vehicle_Details VALUES (78,'Two Wheeler','Vehicle_78','Bentley',4,'High damage',2,9,'LP001121');\n",
      "INSERT INTO Vehicle_Details VALUES (79,'Four Wheeler','Vehicle_79','Tata',6,'Some damage',3,26,'LP001270');\n",
      "INSERT INTO Vehicle_Details VALUES (80,'Four Wheeler','Vehicle_80','Maruti',6,'Some damage',2,28,'LP001067');\n",
      "INSERT INTO Vehicle_Details VALUES (81,'Four Wheeler','Vehicle_81','Mazda',1,'High damage',2,8,'LP001287');\n",
      "INSERT INTO Vehicle_Details VALUES (82,'Two Wheeler','Vehicle_82','Lamborghini',6,'No damage',3,47,'LP001054');\n",
      "INSERT INTO Vehicle_Details VALUES (83,'Two Wheeler','Vehicle_83','Maruti',3,'No damage',2,46,'LP001220');\n",
      "INSERT INTO Vehicle_Details VALUES (84,'Four Wheeler','Vehicle_84','Honda',5,'Some damage',1,39,'LP001149');\n",
      "INSERT INTO Vehicle_Details VALUES (85,'Two Wheeler','Vehicle_85','Audi',6,'No damage',2,12,'LP001055');\n",
      "INSERT INTO Vehicle_Details VALUES (86,'Two Wheeler','Vehicle_86','Lamborghini',1,'No damage',1,10,'LP001051');\n",
      "INSERT INTO Vehicle_Details VALUES (87,'Two Wheeler','Vehicle_87','Mercedes',2,'High damage',2,6,'LP001291');\n",
      "INSERT INTO Vehicle_Details VALUES (88,'Four Wheeler','Vehicle_88','Bentley',4,'No damage',2,18,'LP001291');\n",
      "INSERT INTO Vehicle_Details VALUES (89,'Two Wheeler','Vehicle_89','Mustang',6,'No damage',2,40,'LP001055');\n",
      "INSERT INTO Vehicle_Details VALUES (90,'Two Wheeler','Vehicle_90','Bentley',5,'No damage',1,21,'LP001078');\n",
      "INSERT INTO Vehicle_Details VALUES (91,'Four Wheeler','Vehicle_91','Toyota',7,'High damage',3,46,'LP001105');\n",
      "INSERT INTO Vehicle_Details VALUES (92,'Four Wheeler','Vehicle_92','Honda',4,'High damage',3,25,'LP001153');\n",
      "INSERT INTO Vehicle_Details VALUES (93,'Four Wheeler','Vehicle_93','Mercedes',7,'No damage',2,8,'LP001108');\n",
      "INSERT INTO Vehicle_Details VALUES (94,'Four Wheeler','Vehicle_94','Maruti',2,'High damage',3,8,'LP001190');\n",
      "INSERT INTO Vehicle_Details VALUES (95,'Four Wheeler','Vehicle_95','Mazda',7,'Some damage',3,16,'LP001221');\n",
      "INSERT INTO Vehicle_Details VALUES (96,'Two Wheeler','Vehicle_96','Lincoln',5,'No damage',2,4,'LP001163');\n",
      "INSERT INTO Vehicle_Details VALUES (97,'Four Wheeler','Vehicle_97','Toyota',1,'No damage',1,49,'LP001128');\n",
      "INSERT INTO Vehicle_Details VALUES (98,'Four Wheeler','Vehicle_98','BMW',4,'High damage',3,25,'LP001083');\n",
      "INSERT INTO Vehicle_Details VALUES (99,'Two Wheeler','Vehicle_99','Mazda',7,'High damage',2,4,'LP001015');\n",
      "INSERT INTO Vehicle_Details VALUES (100,'Two Wheeler','Vehicle_100','Mercedes',2,'High damage',1,41,'LP001185');\n"
     ]
    }
   ],
   "source": [
    "#creating INSERT SQL file for Vehicle_Details table\n",
    "for Asset_id, Model_type, Name, Manufacturer, Age, Damage, Owner_number, Holder_id, LoanId  in df.values.tolist():\n",
    "    print(\"INSERT INTO Vehicle_Details VALUES ({},'{}','{}','{}',{},'{}',{},{},'{}');\".format(Asset_id, Model_type, Name, Manufacturer, Age, Damage, Owner_number, Holder_id, LoanId))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working on Home_Details Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Asset_id                                            Address  Carpet_area  \\\n",
      "0       1111  3009 Danielle Center Suite 308\\nNorth Jennifer...         40.0   \n",
      "1       1112  748 Castillo Divide Suite 510\\nLake Kristybury...         42.0   \n",
      "2       1113  001 Morgan Views Apt. 731\\nNew Kimberlychester...         45.0   \n",
      "3       1114  9520 George Summit Suite 971\\nGuerreroburgh, A...         46.0   \n",
      "4       1115  061 Brown Mountains Apt. 800\\nSouth Christinec...         55.0   \n",
      "5       1116       3922 Karen Mountain\\nKatherineport, DC 40003         55.0   \n",
      "6       1117  0135 Foster Prairie Suite 021\\nBrittanyside, A...         60.0   \n",
      "7       1118             32563 Lacey Shoal\\nJamesfort, NE 24868         62.0   \n",
      "8       1119     4809 Spears Walks\\nCunninghamchester, TX 74179         64.0   \n",
      "9       1120            83168 Arnold Forge\\nYoungberg, IA 97019         65.0   \n",
      "10      1121                        USNV Caldwell\\nFPO AE 27939         65.0   \n",
      "11      1122  45598 Christopher Passage\\nEast Joannaland, FM...         65.0   \n",
      "12      1123            94552 Brandon Field\\nOrrhaven, NC 19954         65.0   \n",
      "13      1124          23332 Amber Terrace\\nShelbyside, MA 85270         65.0   \n",
      "14      1125            01564 Jeremy Road\\nVaughnside, FM 93776         65.0   \n",
      "15      1126  630 Donna Corner Suite 932\\nLake Robert, AK 77440         65.0   \n",
      "16      1127               284 Burch Manor\\nKevinbury, UT 57161         67.0   \n",
      "17      1128  8691 Zamora Locks Apt. 105\\nSouth Caleb, DC 82635         68.0   \n",
      "18      1129  18786 Brown Well Suite 770\\nWilliamsborough, N...         70.0   \n",
      "19      1130  127 Victor Causeway Apt. 899\\nDavidville, CT 1...         70.0   \n",
      "20      1131    807 David Brook Apt. 212\\nWest Alyssa, PW 40731         70.0   \n",
      "21      1132  97225 Jennifer Prairie Apt. 772\\nWilliamside, ...         70.0   \n",
      "22      1133  73758 William Plains Apt. 756\\nPort Angela, HI...         70.0   \n",
      "23      1134             55480 Huang Stream\\nClaybury, MT 53758         70.0   \n",
      "24      1135    295 Pamela Port Apt. 786\\nKathrynside, WV 19630         70.0   \n",
      "25      1136   0096 Matthew Springs\\nNorth Nathanview, MT 41960         73.0   \n",
      "26      1137       3514 Moody Ways Apt. 592\\nRyanland, IN 03828         75.0   \n",
      "27      1138               3737 Horton Run\\nDavidstad, MI 16684         75.0   \n",
      "28      1139          300 Sean Crossing\\nWest Gregory, IN 74062         75.0   \n",
      "29      1140            7160 Howe Islands\\nWest Kevin, VT 58443         75.0   \n",
      "30      1141  6695 Olson Flat Apt. 198\\nWest Connieborough, ...         75.0   \n",
      "31      1142  198 Baldwin Alley Suite 153\\nPort Lindseyport,...         80.0   \n",
      "32      1143  573 Matthew Valleys Apt. 703\\nWest Brenda, TN ...         80.0   \n",
      "33      1144  3352 Johnson Track Apt. 498\\nStaceyfort, AK 76235         80.0   \n",
      "34      1145  8739 Crawford Villages\\nEast Beckyburgh, FM 17594         80.0   \n",
      "35      1146  36129 Daniels Gateway Suite 721\\nMedinaton, DC...         80.0   \n",
      "36      1147        696 Barker Spurs\\nEast Tannerport, FL 70496         80.0   \n",
      "37      1148  322 Austin Island Suite 372\\nMillerberg, WY 43411         80.0   \n",
      "38      1149          5766 Teresa Ports\\nMartinezside, ND 91968         82.0   \n",
      "39      1150  07244 Jennifer Branch Suite 737\\nLeslieton, AZ...         83.0   \n",
      "40      1151  9644 Kenneth Terrace Apt. 157\\nKaitlynland, NJ...         84.0   \n",
      "41      1152  11841 Gregory Roads Suite 460\\nGillburgh, UT 0...         85.0   \n",
      "42      1153  676 Howell Road Suite 490\\nEast Amberview, MT ...         85.0   \n",
      "43      1154           782 Christine Spur\\nJacobshire, AZ 33859         86.0   \n",
      "44      1155              287 Kramer Burg\\nMillerbury, NE 21755         90.0   \n",
      "45      1156                   Unit 7296 Box 0767\\nDPO AP 85217         90.0   \n",
      "46      1157           06065 Vincent Pines\\nJohnburgh, WA 11007         90.0   \n",
      "47      1158             885 Brock Trail\\nWilliamston, UT 62571         90.0   \n",
      "48      1159                   Unit 3885 Box 7739\\nDPO AP 55204         90.0   \n",
      "49      1160                            USS Perez\\nFPO AE 25873         95.0   \n",
      "\n",
      "   Construction_type  Estimated_market_value  Year_built  Holder_id    LoanId  \n",
      "0                Old                  385949          18          7  LP001226  \n",
      "1                New                  184066           2         48  LP001287  \n",
      "2                New                  217377           5         14  LP001210  \n",
      "3                New                  169897           4          3  LP001015  \n",
      "4                Old                  109943          11         18  LP001242  \n",
      "5                New                  292367           3          7  LP001108  \n",
      "6                New                  369417           4         39  LP001055  \n",
      "7                Old                  101699          13         16  LP001163  \n",
      "8                New                  389887           2         42  LP001153  \n",
      "9                New                   75642           8         47  LP001031  \n",
      "10               Old                  212392          14         22  LP001231  \n",
      "11               New                  390273           5          6  LP001312  \n",
      "12               Old                  438419          14         39  LP001176  \n",
      "13               Old                  162020          15          7  LP001094  \n",
      "14               Old                  495857          14         38  LP001242  \n",
      "15               Old                  133986          12         35  LP001108  \n",
      "16               New                  107756           2         31  LP001096  \n",
      "17               Old                  263533          13         41  LP001099  \n",
      "18               Old                  164160          14         47  LP001268  \n",
      "19               New                  317891           1         14  LP001220  \n",
      "20               Old                  410420          18         47  LP001067  \n",
      "21               Old                   52771          15          3  LP001298  \n",
      "22               Old                  472568          16          7  LP001067  \n",
      "23               Old                  101893          11         31  LP001270  \n",
      "24               New                  407567          10         36  LP001121  \n",
      "25               Old                  266015          12          7  LP001185  \n",
      "26               Old                  289124          20         14  LP001232  \n",
      "27               Old                   79426          14          3  LP001022  \n",
      "28               New                   97341           3         10  LP001312  \n",
      "29               New                   96660           8         17  LP001054  \n",
      "30               Old                  394416          20         35  LP001187  \n",
      "31               Old                   79251          17         45  LP001176  \n",
      "32               New                  403847           7         30  LP001237  \n",
      "33               Old                  299328          18         20  LP001298  \n",
      "34               Old                  224027          18         28  LP001105  \n",
      "35               Old                  248709          18         42  LP001153  \n",
      "36               New                  125109           5         16  LP001094  \n",
      "37               Old                  295590          19         27  LP001270  \n",
      "38               New                  209576           2         23  LP001287  \n",
      "39               New                  204241           2         34  LP001115  \n",
      "40               Old                   55990          15         26  LP001054  \n",
      "41               New                   56627           8         16  LP001210  \n",
      "42               Old                  290656          12         14  LP001022  \n",
      "43               New                  149871           2         32  LP001203  \n",
      "44               Old                  240705          14          5  LP001059  \n",
      "45               New                  214155           1         23  LP001230  \n",
      "46               New                  240480           3         20  LP001270  \n",
      "47               New                  323596           2         28  LP001208  \n",
      "48               New                   84344           3         16  LP001284  \n",
      "49               New                  191756           2         49  LP001031  \n"
     ]
    }
   ],
   "source": [
    "# Working on Home_Details\n",
    "# I'll be using a file that i got from kaggle and also generating some random data for missing columns\n",
    "# reference - https://www.kaggle.com/datasets/emrahaydemr/home-sales-data-details-in-istanbul\n",
    "\n",
    "\n",
    "holder_ids = list(range(1, 51))\n",
    "loan_ids = loan_id_list\n",
    "\n",
    "# Initialize the Faker generator for USA addresses\n",
    "fake = Faker('en_US')\n",
    "\n",
    "# Assuming 'your_data.csv' is the file containing your data\n",
    "df = pd.read_csv('Home Sale Data.csv', delimiter=';')\n",
    "\n",
    "# Create a new DataFrame with the desired columns and only 50 rows\n",
    "new_df = pd.DataFrame(columns=['Asset_id', 'Address', 'Carpet_area', 'Construction_type', 'Estimated_market_value',\n",
    "                               'Year_built', 'Holder_id', 'LoanId'])\n",
    "\n",
    "# Set the primary key (Asset_id) as integers starting from 1\n",
    "new_df['Asset_id'] = np.arange(1111, 1161)\n",
    "\n",
    "# Use the columns that are similar to the attributes in the table\n",
    "new_df['Carpet_area'] = df['m (Net)'].head(50)  # Assuming 'm (Net)' is the carpet area column\n",
    "new_df['Estimated_market_value'] = np.random.randint(50000, 500000, 50)  # Random market values\n",
    "\n",
    "# Use the provided 'year' list for the 'Year_built' column\n",
    "new_df['Year_built'] = random.choices([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], k=50)\n",
    "\n",
    "# Set Construction_type as 'Old' if Year_built > 10, else 'New'\n",
    "new_df['Construction_type'] = np.where(new_df['Year_built'] > 10, 'Old', 'New')\n",
    "\n",
    "# Generate random Holder_id and LoanId based on the provided lists\n",
    "new_df['Holder_id'] = random.choices(holder_ids, k=50)\n",
    "new_df['LoanId'] = random.choices(loan_ids, k=50)\n",
    "\n",
    "# Generate random USA addresses\n",
    "new_df['Address'] = [fake.address() for _ in range(50)]\n",
    "\n",
    "\n",
    "print(new_df)\n",
    "new_df.to_csv('Home_Details.csv', index=False)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT INTO Home_Details VALUES (1111,'3009 Danielle Center Suite 308\n",
      "North Jenniferland, ID 76511',40.0,'Old',385949,18,7,'LP001226');\n",
      "INSERT INTO Home_Details VALUES (1112,'748 Castillo Divide Suite 510\n",
      "Lake Kristybury, MH 32946',42.0,'New',184066,2,48,'LP001287');\n",
      "INSERT INTO Home_Details VALUES (1113,'001 Morgan Views Apt. 731\n",
      "New Kimberlychester, MT 37668',45.0,'New',217377,5,14,'LP001210');\n",
      "INSERT INTO Home_Details VALUES (1114,'9520 George Summit Suite 971\n",
      "Guerreroburgh, AZ 66844',46.0,'New',169897,4,3,'LP001015');\n",
      "INSERT INTO Home_Details VALUES (1115,'061 Brown Mountains Apt. 800\n",
      "South Christinechester, CO 90689',55.0,'Old',109943,11,18,'LP001242');\n",
      "INSERT INTO Home_Details VALUES (1116,'3922 Karen Mountain\n",
      "Katherineport, DC 40003',55.0,'New',292367,3,7,'LP001108');\n",
      "INSERT INTO Home_Details VALUES (1117,'0135 Foster Prairie Suite 021\n",
      "Brittanyside, AK 29112',60.0,'New',369417,4,39,'LP001055');\n",
      "INSERT INTO Home_Details VALUES (1118,'32563 Lacey Shoal\n",
      "Jamesfort, NE 24868',62.0,'Old',101699,13,16,'LP001163');\n",
      "INSERT INTO Home_Details VALUES (1119,'4809 Spears Walks\n",
      "Cunninghamchester, TX 74179',64.0,'New',389887,2,42,'LP001153');\n",
      "INSERT INTO Home_Details VALUES (1120,'83168 Arnold Forge\n",
      "Youngberg, IA 97019',65.0,'New',75642,8,47,'LP001031');\n",
      "INSERT INTO Home_Details VALUES (1121,'USNV Caldwell\n",
      "FPO AE 27939',65.0,'Old',212392,14,22,'LP001231');\n",
      "INSERT INTO Home_Details VALUES (1122,'45598 Christopher Passage\n",
      "East Joannaland, FM 39512',65.0,'New',390273,5,6,'LP001312');\n",
      "INSERT INTO Home_Details VALUES (1123,'94552 Brandon Field\n",
      "Orrhaven, NC 19954',65.0,'Old',438419,14,39,'LP001176');\n",
      "INSERT INTO Home_Details VALUES (1124,'23332 Amber Terrace\n",
      "Shelbyside, MA 85270',65.0,'Old',162020,15,7,'LP001094');\n",
      "INSERT INTO Home_Details VALUES (1125,'01564 Jeremy Road\n",
      "Vaughnside, FM 93776',65.0,'Old',495857,14,38,'LP001242');\n",
      "INSERT INTO Home_Details VALUES (1126,'630 Donna Corner Suite 932\n",
      "Lake Robert, AK 77440',65.0,'Old',133986,12,35,'LP001108');\n",
      "INSERT INTO Home_Details VALUES (1127,'284 Burch Manor\n",
      "Kevinbury, UT 57161',67.0,'New',107756,2,31,'LP001096');\n",
      "INSERT INTO Home_Details VALUES (1128,'8691 Zamora Locks Apt. 105\n",
      "South Caleb, DC 82635',68.0,'Old',263533,13,41,'LP001099');\n",
      "INSERT INTO Home_Details VALUES (1129,'18786 Brown Well Suite 770\n",
      "Williamsborough, NY 19633',70.0,'Old',164160,14,47,'LP001268');\n",
      "INSERT INTO Home_Details VALUES (1130,'127 Victor Causeway Apt. 899\n",
      "Davidville, CT 18729',70.0,'New',317891,1,14,'LP001220');\n",
      "INSERT INTO Home_Details VALUES (1131,'807 David Brook Apt. 212\n",
      "West Alyssa, PW 40731',70.0,'Old',410420,18,47,'LP001067');\n",
      "INSERT INTO Home_Details VALUES (1132,'97225 Jennifer Prairie Apt. 772\n",
      "Williamside, GU 46081',70.0,'Old',52771,15,3,'LP001298');\n",
      "INSERT INTO Home_Details VALUES (1133,'73758 William Plains Apt. 756\n",
      "Port Angela, HI 90946',70.0,'Old',472568,16,7,'LP001067');\n",
      "INSERT INTO Home_Details VALUES (1134,'55480 Huang Stream\n",
      "Claybury, MT 53758',70.0,'Old',101893,11,31,'LP001270');\n",
      "INSERT INTO Home_Details VALUES (1135,'295 Pamela Port Apt. 786\n",
      "Kathrynside, WV 19630',70.0,'New',407567,10,36,'LP001121');\n",
      "INSERT INTO Home_Details VALUES (1136,'0096 Matthew Springs\n",
      "North Nathanview, MT 41960',73.0,'Old',266015,12,7,'LP001185');\n",
      "INSERT INTO Home_Details VALUES (1137,'3514 Moody Ways Apt. 592\n",
      "Ryanland, IN 03828',75.0,'Old',289124,20,14,'LP001232');\n",
      "INSERT INTO Home_Details VALUES (1138,'3737 Horton Run\n",
      "Davidstad, MI 16684',75.0,'Old',79426,14,3,'LP001022');\n",
      "INSERT INTO Home_Details VALUES (1139,'300 Sean Crossing\n",
      "West Gregory, IN 74062',75.0,'New',97341,3,10,'LP001312');\n",
      "INSERT INTO Home_Details VALUES (1140,'7160 Howe Islands\n",
      "West Kevin, VT 58443',75.0,'New',96660,8,17,'LP001054');\n",
      "INSERT INTO Home_Details VALUES (1141,'6695 Olson Flat Apt. 198\n",
      "West Connieborough, KY 44936',75.0,'Old',394416,20,35,'LP001187');\n",
      "INSERT INTO Home_Details VALUES (1142,'198 Baldwin Alley Suite 153\n",
      "Port Lindseyport, IN 82950',80.0,'Old',79251,17,45,'LP001176');\n",
      "INSERT INTO Home_Details VALUES (1143,'573 Matthew Valleys Apt. 703\n",
      "West Brenda, TN 22751',80.0,'New',403847,7,30,'LP001237');\n",
      "INSERT INTO Home_Details VALUES (1144,'3352 Johnson Track Apt. 498\n",
      "Staceyfort, AK 76235',80.0,'Old',299328,18,20,'LP001298');\n",
      "INSERT INTO Home_Details VALUES (1145,'8739 Crawford Villages\n",
      "East Beckyburgh, FM 17594',80.0,'Old',224027,18,28,'LP001105');\n",
      "INSERT INTO Home_Details VALUES (1146,'36129 Daniels Gateway Suite 721\n",
      "Medinaton, DC 21537',80.0,'Old',248709,18,42,'LP001153');\n",
      "INSERT INTO Home_Details VALUES (1147,'696 Barker Spurs\n",
      "East Tannerport, FL 70496',80.0,'New',125109,5,16,'LP001094');\n",
      "INSERT INTO Home_Details VALUES (1148,'322 Austin Island Suite 372\n",
      "Millerberg, WY 43411',80.0,'Old',295590,19,27,'LP001270');\n",
      "INSERT INTO Home_Details VALUES (1149,'5766 Teresa Ports\n",
      "Martinezside, ND 91968',82.0,'New',209576,2,23,'LP001287');\n",
      "INSERT INTO Home_Details VALUES (1150,'07244 Jennifer Branch Suite 737\n",
      "Leslieton, AZ 59679',83.0,'New',204241,2,34,'LP001115');\n",
      "INSERT INTO Home_Details VALUES (1151,'9644 Kenneth Terrace Apt. 157\n",
      "Kaitlynland, NJ 45793',84.0,'Old',55990,15,26,'LP001054');\n",
      "INSERT INTO Home_Details VALUES (1152,'11841 Gregory Roads Suite 460\n",
      "Gillburgh, UT 09524',85.0,'New',56627,8,16,'LP001210');\n",
      "INSERT INTO Home_Details VALUES (1153,'676 Howell Road Suite 490\n",
      "East Amberview, MT 76101',85.0,'Old',290656,12,14,'LP001022');\n",
      "INSERT INTO Home_Details VALUES (1154,'782 Christine Spur\n",
      "Jacobshire, AZ 33859',86.0,'New',149871,2,32,'LP001203');\n",
      "INSERT INTO Home_Details VALUES (1155,'287 Kramer Burg\n",
      "Millerbury, NE 21755',90.0,'Old',240705,14,5,'LP001059');\n",
      "INSERT INTO Home_Details VALUES (1156,'Unit 7296 Box 0767\n",
      "DPO AP 85217',90.0,'New',214155,1,23,'LP001230');\n",
      "INSERT INTO Home_Details VALUES (1157,'06065 Vincent Pines\n",
      "Johnburgh, WA 11007',90.0,'New',240480,3,20,'LP001270');\n",
      "INSERT INTO Home_Details VALUES (1158,'885 Brock Trail\n",
      "Williamston, UT 62571',90.0,'New',323596,2,28,'LP001208');\n",
      "INSERT INTO Home_Details VALUES (1159,'Unit 3885 Box 7739\n",
      "DPO AP 55204',90.0,'New',84344,3,16,'LP001284');\n",
      "INSERT INTO Home_Details VALUES (1160,'USS Perez\n",
      "FPO AE 25873',95.0,'New',191756,2,49,'LP001031');\n"
     ]
    }
   ],
   "source": [
    "#creating INSERT SQL file for Home_Details table\n",
    "for Asset_id, Address, Carpet_area, Construction_type, Estimated_market_value, Year_built, Holder_id, LoanId  in new_df.values.tolist():\n",
    "    print(\"INSERT INTO Home_Details VALUES ({},'{}',{},'{}',{},{},{},'{}');\".format(Asset_id, Address, Carpet_area, Construction_type, Estimated_market_value, Year_built, Holder_id, LoanId))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working Claim Table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Claim_id  Claim_amount        Date  Holder_id\n",
      "0       8270          4943  2022-01-01         32\n",
      "1       1860         24939  2022-01-15          2\n",
      "2       6390         20457  2022-01-30         14\n",
      "3       6191          2021  2022-02-14         12\n",
      "4       6734         12653  2022-03-01         37\n",
      "5       7265         44573  2022-03-16         34\n",
      "6       1466         14417  2022-03-31         45\n",
      "7       5426         41757  2022-04-15          5\n",
      "8       6578         10692  2022-04-30         22\n",
      "9       9322         46758  2022-05-14          2\n",
      "10      2685          7873  2022-05-29         11\n",
      "11      1769          6675  2022-06-13         26\n",
      "12      7949          1161  2022-06-28          2\n",
      "13      3433         38065  2022-07-13         10\n",
      "14      6311         27557  2022-07-28         33\n",
      "15      6051         34763  2022-08-12         28\n",
      "16      7420         33606  2022-08-27         12\n",
      "17      2184         12534  2022-09-10         30\n",
      "18      5555         30127  2022-09-25         41\n",
      "19      4385         41397  2022-10-10          1\n",
      "20      7396         26851  2022-10-25         41\n",
      "21      9666          2016  2022-11-09         35\n",
      "22      3558         25253  2022-11-24         18\n",
      "23      8849         25276  2022-12-09          8\n",
      "24      3047         24247  2022-12-24         48\n",
      "25      3747         25300  2023-01-07         17\n",
      "26      1189          9529  2023-01-22          5\n",
      "27      3734         18262  2023-02-06          5\n",
      "28      4005         10268  2023-02-21         43\n",
      "29      5658         22271  2023-03-08         31\n",
      "30      2899         13185  2023-03-23         41\n",
      "31      8734         22243  2023-04-07         37\n",
      "32      2267         40099  2023-04-22         27\n",
      "33      2528          9571  2023-05-06         49\n",
      "34      4556         40976  2023-05-21         19\n",
      "35      4890         39044  2023-06-05         28\n",
      "36      9838         49984  2023-06-20         42\n",
      "37      6393         41774  2023-07-05         31\n",
      "38      9792          3568  2023-07-20         44\n",
      "39      9433          3027  2023-08-04         29\n",
      "40      8513          3695  2023-08-19         36\n",
      "41      3612         49190  2023-09-02          3\n",
      "42      8041          6258  2023-09-17         12\n",
      "43      7235         23002  2023-10-02         15\n",
      "44      6486         40504  2023-10-17          4\n",
      "45      8099         34159  2023-11-01         12\n",
      "46      1775         14986  2023-11-16          6\n",
      "47      9226         13666  2023-12-01         14\n",
      "48      4152         39660  2023-12-16         32\n",
      "49      2585          4561  2023-12-31         19\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Generate random data for the Claim table\n",
    "fake = Faker()\n",
    "num_records = 50  # Limit to 50 rows\n",
    "\n",
    "# Generate random Claim_id, Claim_amount, Date, and Holder_id\n",
    "claim_ids = np.random.randint(1000, 10000, num_records)\n",
    "claim_amounts = np.random.randint(1000, 50000, num_records)\n",
    "dates = pd.date_range(start='2022-01-01', end='2023-12-31', periods=num_records)\n",
    "holder_ids = random.choices(range(1, 51), k=num_records)\n",
    "\n",
    "# Create a DataFrame with the generated data\n",
    "claim_data = pd.DataFrame({\n",
    "    'Claim_id': claim_ids,\n",
    "    'Claim_amount': claim_amounts,\n",
    "    'Date': dates,\n",
    "    'Holder_id': holder_ids\n",
    "})\n",
    "\n",
    "# Format the Date column to YYYY-MM-DD\n",
    "claim_data['Date'] = claim_data['Date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Print or use the resulting DataFrame as needed\n",
    "print(claim_data)\n",
    "\n",
    "claim_data.to_csv('Claim.csv', index=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT INTO Claim VALUES (8270,4943,'2022-01-01',32);\n",
      "INSERT INTO Claim VALUES (1860,24939,'2022-01-15',2);\n",
      "INSERT INTO Claim VALUES (6390,20457,'2022-01-30',14);\n",
      "INSERT INTO Claim VALUES (6191,2021,'2022-02-14',12);\n",
      "INSERT INTO Claim VALUES (6734,12653,'2022-03-01',37);\n",
      "INSERT INTO Claim VALUES (7265,44573,'2022-03-16',34);\n",
      "INSERT INTO Claim VALUES (1466,14417,'2022-03-31',45);\n",
      "INSERT INTO Claim VALUES (5426,41757,'2022-04-15',5);\n",
      "INSERT INTO Claim VALUES (6578,10692,'2022-04-30',22);\n",
      "INSERT INTO Claim VALUES (9322,46758,'2022-05-14',2);\n",
      "INSERT INTO Claim VALUES (2685,7873,'2022-05-29',11);\n",
      "INSERT INTO Claim VALUES (1769,6675,'2022-06-13',26);\n",
      "INSERT INTO Claim VALUES (7949,1161,'2022-06-28',2);\n",
      "INSERT INTO Claim VALUES (3433,38065,'2022-07-13',10);\n",
      "INSERT INTO Claim VALUES (6311,27557,'2022-07-28',33);\n",
      "INSERT INTO Claim VALUES (6051,34763,'2022-08-12',28);\n",
      "INSERT INTO Claim VALUES (7420,33606,'2022-08-27',12);\n",
      "INSERT INTO Claim VALUES (2184,12534,'2022-09-10',30);\n",
      "INSERT INTO Claim VALUES (5555,30127,'2022-09-25',41);\n",
      "INSERT INTO Claim VALUES (4385,41397,'2022-10-10',1);\n",
      "INSERT INTO Claim VALUES (7396,26851,'2022-10-25',41);\n",
      "INSERT INTO Claim VALUES (9666,2016,'2022-11-09',35);\n",
      "INSERT INTO Claim VALUES (3558,25253,'2022-11-24',18);\n",
      "INSERT INTO Claim VALUES (8849,25276,'2022-12-09',8);\n",
      "INSERT INTO Claim VALUES (3047,24247,'2022-12-24',48);\n",
      "INSERT INTO Claim VALUES (3747,25300,'2023-01-07',17);\n",
      "INSERT INTO Claim VALUES (1189,9529,'2023-01-22',5);\n",
      "INSERT INTO Claim VALUES (3734,18262,'2023-02-06',5);\n",
      "INSERT INTO Claim VALUES (4005,10268,'2023-02-21',43);\n",
      "INSERT INTO Claim VALUES (5658,22271,'2023-03-08',31);\n",
      "INSERT INTO Claim VALUES (2899,13185,'2023-03-23',41);\n",
      "INSERT INTO Claim VALUES (8734,22243,'2023-04-07',37);\n",
      "INSERT INTO Claim VALUES (2267,40099,'2023-04-22',27);\n",
      "INSERT INTO Claim VALUES (2528,9571,'2023-05-06',49);\n",
      "INSERT INTO Claim VALUES (4556,40976,'2023-05-21',19);\n",
      "INSERT INTO Claim VALUES (4890,39044,'2023-06-05',28);\n",
      "INSERT INTO Claim VALUES (9838,49984,'2023-06-20',42);\n",
      "INSERT INTO Claim VALUES (6393,41774,'2023-07-05',31);\n",
      "INSERT INTO Claim VALUES (9792,3568,'2023-07-20',44);\n",
      "INSERT INTO Claim VALUES (9433,3027,'2023-08-04',29);\n",
      "INSERT INTO Claim VALUES (8513,3695,'2023-08-19',36);\n",
      "INSERT INTO Claim VALUES (3612,49190,'2023-09-02',3);\n",
      "INSERT INTO Claim VALUES (8041,6258,'2023-09-17',12);\n",
      "INSERT INTO Claim VALUES (7235,23002,'2023-10-02',15);\n",
      "INSERT INTO Claim VALUES (6486,40504,'2023-10-17',4);\n",
      "INSERT INTO Claim VALUES (8099,34159,'2023-11-01',12);\n",
      "INSERT INTO Claim VALUES (1775,14986,'2023-11-16',6);\n",
      "INSERT INTO Claim VALUES (9226,13666,'2023-12-01',14);\n",
      "INSERT INTO Claim VALUES (4152,39660,'2023-12-16',32);\n",
      "INSERT INTO Claim VALUES (2585,4561,'2023-12-31',19);\n"
     ]
    }
   ],
   "source": [
    "#creating INSERT SQL file for Claim table\n",
    "for Claim_id, Claim_amount, Date, Holder_id  in claim_data.values.tolist():\n",
    "    print(\"INSERT INTO Claim VALUES ({},{},'{}',{});\".format(Claim_id, Claim_amount, Date, Holder_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working on Transactions Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Transaction_id        Date status_of_transaction  Amount  Customer_id  \\\n",
      "405253         098725  2017-03-10               Pending   49668       719439   \n",
      "151544         603071  2017-03-21               Pending   18303       345273   \n",
      "426715         136633  2017-07-11                Failed   16434       249650   \n",
      "222061         152754  2017-04-29                Failed   46570       871428   \n",
      "266453         616393  2017-05-16                Failed   44055       555849   \n",
      "335989         926484  2017-05-08             Completed   15151       640537   \n",
      "97388          205872  2017-10-01                Failed    2756       915790   \n",
      "303029         586079  2017-07-28                Failed   24303       867938   \n",
      "75745          028129  2017-01-31                Failed   29118       555849   \n",
      "189429         793896  2017-09-05                Failed    6691       621200   \n",
      "80497          830021  2017-01-20             Completed   17164       293654   \n",
      "124804         726836  2017-08-30               Pending   26063       358893   \n",
      "41887          775668  2017-10-01                Failed   33701       365390   \n",
      "350053         254957  2017-08-19               Pending   14749       867938   \n",
      "315587         189198  2017-08-19             Completed   24353       389080   \n",
      "11952          454793  2017-06-09               Pending    1660        77471   \n",
      "63008          271127  2017-09-01                Failed   12003       733572   \n",
      "403690         309030  2017-10-21               Pending   16926       555849   \n",
      "213659         409634  2017-09-05               Pending   23282       847339   \n",
      "306800         557235  2017-02-08             Completed   30481       365390   \n",
      "306540         451003  2017-11-10                Failed   37036       974101   \n",
      "22531          132434  2017-04-01               Pending    1420        58082   \n",
      "277639         797901  2017-11-21             Completed   37535       871428   \n",
      "435962         603560  2017-12-30                Failed   44263       871428   \n",
      "353425         651645  2017-08-17                Failed   45991       871428   \n",
      "21565          306533  2017-06-01             Completed   40435       176254   \n",
      "195155         614899  2017-09-05             Completed   35387       492977   \n",
      "48866          388314  2017-01-20             Completed   46863        74341   \n",
      "247835         269945  2017-10-17               Pending    6350       352841   \n",
      "220368         466018  2017-04-13               Pending   26411       871428   \n",
      "313004         666273  2017-04-07             Completed   19758       974101   \n",
      "87138          546336  2017-10-02               Pending    2896       352841   \n",
      "236755         651163  2017-05-23             Completed    9155       915790   \n",
      "298584         775830  2017-03-10                Failed    6818       621200   \n",
      "33183          321230  2017-08-30                Failed   31943       415216   \n",
      "278925         570276  2017-05-19                Failed   45002       249650   \n",
      "251336         468560  2017-03-05                Failed   23737       640537   \n",
      "364890         273256  2017-08-30             Completed   15958        77471   \n",
      "186966         395515  2017-05-19               Pending   48261       389080   \n",
      "271953         613772  2017-05-16                Failed   42766       621200   \n",
      "275056         943192  2017-04-07               Pending   43681       293654   \n",
      "192841         056476  2017-04-17               Pending   15107       293654   \n",
      "143798         865643  2017-06-03               Pending    8480       979749   \n",
      "147476         221016  2017-06-09                Failed   26937       532909   \n",
      "435692         781085  2017-10-17             Completed   37479       554593   \n",
      "411873         299534  2017-07-10             Completed   21790       345273   \n",
      "479224         674674  2017-12-29               Pending    5244       538409   \n",
      "403800         661066  2017-03-10                Failed   18612       872585   \n",
      "73040          082963  2017-11-01                Failed    6382       719439   \n",
      "246787         729563  2017-12-05                Failed    1872       872585   \n",
      "\n",
      "        Holder_id  \n",
      "405253         27  \n",
      "151544         28  \n",
      "426715         21  \n",
      "222061          2  \n",
      "266453         14  \n",
      "335989          6  \n",
      "97388          30  \n",
      "303029         15  \n",
      "75745           2  \n",
      "189429         20  \n",
      "80497          14  \n",
      "124804         24  \n",
      "41887          50  \n",
      "350053         18  \n",
      "315587          9  \n",
      "11952          34  \n",
      "63008          36  \n",
      "403690         43  \n",
      "213659         21  \n",
      "306800          4  \n",
      "306540         31  \n",
      "22531          41  \n",
      "277639         17  \n",
      "435962         19  \n",
      "353425         33  \n",
      "21565          41  \n",
      "195155         26  \n",
      "48866          29  \n",
      "247835         27  \n",
      "220368         50  \n",
      "313004         11  \n",
      "87138          32  \n",
      "236755          7  \n",
      "298584          3  \n",
      "33183           6  \n",
      "278925         40  \n",
      "251336         20  \n",
      "364890         16  \n",
      "186966         33  \n",
      "271953         23  \n",
      "275056          9  \n",
      "192841         29  \n",
      "143798         11  \n",
      "147476          6  \n",
      "435692          3  \n",
      "411873         26  \n",
      "479224         45  \n",
      "403800         22  \n",
      "73040          12  \n",
      "246787         42  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# I'll be populating some columns from a Andhra_Health_Data.csv and some columns will be generated manually\n",
    "# reference - https://www.kaggle.com/datasets/phiitm/andhra-pradesh-health-data\n",
    "\n",
    "#The file used below has to be downloaded before running the code again\n",
    "# Read data from Andhra_Health_Data.csv\n",
    "health_data = pd.read_csv('/Users/karanbadlani/Desktop/Andhra_Health_Data.csv')\n",
    "\n",
    "# Define lists for customer_id and holder_id\n",
    "customer_ids = c_id_list\n",
    "\n",
    "holder_ids = list(range(1, 51))\n",
    "\n",
    "# Generate random data for other columns\n",
    "num_transactions = len(health_data)\n",
    "transaction_ids = [str(random.randint(0, 999999)).zfill(6) for _ in range(num_transactions)]\n",
    "dates = pd.to_datetime(health_data['CLAIM_DATE']).dt.date\n",
    "status_of_transactions = random.choices(['Completed', 'Pending', 'Failed'], k=num_transactions)\n",
    "amounts = np.random.randint(1000, 50000, num_transactions)\n",
    "customer_ids_random = random.choices(customer_ids, k=num_transactions)\n",
    "holder_ids_random = random.choices(holder_ids, k=num_transactions)\n",
    "\n",
    "# Create the Transactions DataFrame\n",
    "transactions_data = pd.DataFrame({\n",
    "    'Transaction_id': transaction_ids,\n",
    "    'Date': dates,\n",
    "    'status_of_transaction': status_of_transactions,\n",
    "    'Amount': amounts,\n",
    "    'Customer_id': customer_ids_random,\n",
    "    'Holder_id': holder_ids_random\n",
    "})\n",
    "\n",
    "# Save only 50 random rows to a CSV file\n",
    "transactions_data_50_rows = transactions_data.sample(n=50)\n",
    "transactions_data_50_rows.to_csv('Transactions.csv', index=False)\n",
    "\n",
    "# Print or use the resulting DataFrame as needed\n",
    "print(transactions_data_50_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT INTO Transactions VALUES (098725,'2017-03-10','Pending',49668,719439,27);\n",
      "INSERT INTO Transactions VALUES (603071,'2017-03-21','Pending',18303,345273,28);\n",
      "INSERT INTO Transactions VALUES (136633,'2017-07-11','Failed',16434,249650,21);\n",
      "INSERT INTO Transactions VALUES (152754,'2017-04-29','Failed',46570,871428,2);\n",
      "INSERT INTO Transactions VALUES (616393,'2017-05-16','Failed',44055,555849,14);\n",
      "INSERT INTO Transactions VALUES (926484,'2017-05-08','Completed',15151,640537,6);\n",
      "INSERT INTO Transactions VALUES (205872,'2017-10-01','Failed',2756,915790,30);\n",
      "INSERT INTO Transactions VALUES (586079,'2017-07-28','Failed',24303,867938,15);\n",
      "INSERT INTO Transactions VALUES (028129,'2017-01-31','Failed',29118,555849,2);\n",
      "INSERT INTO Transactions VALUES (793896,'2017-09-05','Failed',6691,621200,20);\n",
      "INSERT INTO Transactions VALUES (830021,'2017-01-20','Completed',17164,293654,14);\n",
      "INSERT INTO Transactions VALUES (726836,'2017-08-30','Pending',26063,358893,24);\n",
      "INSERT INTO Transactions VALUES (775668,'2017-10-01','Failed',33701,365390,50);\n",
      "INSERT INTO Transactions VALUES (254957,'2017-08-19','Pending',14749,867938,18);\n",
      "INSERT INTO Transactions VALUES (189198,'2017-08-19','Completed',24353,389080,9);\n",
      "INSERT INTO Transactions VALUES (454793,'2017-06-09','Pending',1660,77471,34);\n",
      "INSERT INTO Transactions VALUES (271127,'2017-09-01','Failed',12003,733572,36);\n",
      "INSERT INTO Transactions VALUES (309030,'2017-10-21','Pending',16926,555849,43);\n",
      "INSERT INTO Transactions VALUES (409634,'2017-09-05','Pending',23282,847339,21);\n",
      "INSERT INTO Transactions VALUES (557235,'2017-02-08','Completed',30481,365390,4);\n",
      "INSERT INTO Transactions VALUES (451003,'2017-11-10','Failed',37036,974101,31);\n",
      "INSERT INTO Transactions VALUES (132434,'2017-04-01','Pending',1420,58082,41);\n",
      "INSERT INTO Transactions VALUES (797901,'2017-11-21','Completed',37535,871428,17);\n",
      "INSERT INTO Transactions VALUES (603560,'2017-12-30','Failed',44263,871428,19);\n",
      "INSERT INTO Transactions VALUES (651645,'2017-08-17','Failed',45991,871428,33);\n",
      "INSERT INTO Transactions VALUES (306533,'2017-06-01','Completed',40435,176254,41);\n",
      "INSERT INTO Transactions VALUES (614899,'2017-09-05','Completed',35387,492977,26);\n",
      "INSERT INTO Transactions VALUES (388314,'2017-01-20','Completed',46863,74341,29);\n",
      "INSERT INTO Transactions VALUES (269945,'2017-10-17','Pending',6350,352841,27);\n",
      "INSERT INTO Transactions VALUES (466018,'2017-04-13','Pending',26411,871428,50);\n",
      "INSERT INTO Transactions VALUES (666273,'2017-04-07','Completed',19758,974101,11);\n",
      "INSERT INTO Transactions VALUES (546336,'2017-10-02','Pending',2896,352841,32);\n",
      "INSERT INTO Transactions VALUES (651163,'2017-05-23','Completed',9155,915790,7);\n",
      "INSERT INTO Transactions VALUES (775830,'2017-03-10','Failed',6818,621200,3);\n",
      "INSERT INTO Transactions VALUES (321230,'2017-08-30','Failed',31943,415216,6);\n",
      "INSERT INTO Transactions VALUES (570276,'2017-05-19','Failed',45002,249650,40);\n",
      "INSERT INTO Transactions VALUES (468560,'2017-03-05','Failed',23737,640537,20);\n",
      "INSERT INTO Transactions VALUES (273256,'2017-08-30','Completed',15958,77471,16);\n",
      "INSERT INTO Transactions VALUES (395515,'2017-05-19','Pending',48261,389080,33);\n",
      "INSERT INTO Transactions VALUES (613772,'2017-05-16','Failed',42766,621200,23);\n",
      "INSERT INTO Transactions VALUES (943192,'2017-04-07','Pending',43681,293654,9);\n",
      "INSERT INTO Transactions VALUES (056476,'2017-04-17','Pending',15107,293654,29);\n",
      "INSERT INTO Transactions VALUES (865643,'2017-06-03','Pending',8480,979749,11);\n",
      "INSERT INTO Transactions VALUES (221016,'2017-06-09','Failed',26937,532909,6);\n",
      "INSERT INTO Transactions VALUES (781085,'2017-10-17','Completed',37479,554593,3);\n",
      "INSERT INTO Transactions VALUES (299534,'2017-07-10','Completed',21790,345273,26);\n",
      "INSERT INTO Transactions VALUES (674674,'2017-12-29','Pending',5244,538409,45);\n",
      "INSERT INTO Transactions VALUES (661066,'2017-03-10','Failed',18612,872585,22);\n",
      "INSERT INTO Transactions VALUES (082963,'2017-11-01','Failed',6382,719439,12);\n",
      "INSERT INTO Transactions VALUES (729563,'2017-12-05','Failed',1872,872585,42);\n"
     ]
    }
   ],
   "source": [
    "#creating INSERT SQL file for Transactions table\n",
    "for Transaction_id, Date, status_of_transaction, Amount, Customer_id, Holder_id  in transactions_data_50_rows.values.tolist():\n",
    "    print(\"INSERT INTO Transactions VALUES ({},'{}','{}',{},{},{});\".format(Transaction_id, Date, status_of_transaction, Amount, Customer_id, Holder_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working on Report Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the needed Ids and creating a single dataframe\n",
    "Report_id_df = pd.read_csv(\"report_details_data.csv\")\n",
    "Report_id_df = Report_id_df.iloc[:,0]\n",
    "Asset_id_vehicle = pd.read_csv(\"vehicle_details.csv\")\n",
    "Asset_id_vehicle = Asset_id_vehicle.iloc[:,0]\n",
    "Asset_id_home = pd.read_csv(\"Home_Details.csv\")\n",
    "Asset_id_home = Asset_id_home.iloc[:, 0]\n",
    "claim_id = pd.read_csv(\"Claim.csv\")\n",
    "claim_id = claim_id.iloc[: ,0]\n",
    "\n",
    "Report_id_df = Report_id_df.values.tolist()\n",
    "Asset_id_vehicle = Asset_id_vehicle.values.tolist()\n",
    "Asset_id_home = Asset_id_home.values.tolist()\n",
    "claim_id = claim_id.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "print(len(Report_id_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Reports DataFrame\n",
    "Reports_data = pd.DataFrame({\n",
    "    'Report_id': random.choices(Report_id_df, k=30),\n",
    "    'Asset_id_vehicle': random.choices(Asset_id_vehicle, k=30),\n",
    "    'Asset_id_home': random.choices(Asset_id_home, k=30),\n",
    "    'Claim_id': random.choices(claim_id, k=30)\n",
    "})\n",
    "\n",
    "Reports_data.to_csv(\"Reports.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Report_id</th>\n",
       "      <th>Asset_id_vehicle</th>\n",
       "      <th>Asset_id_home</th>\n",
       "      <th>Claim_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>82</td>\n",
       "      <td>1132</td>\n",
       "      <td>6578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>1141</td>\n",
       "      <td>8270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>89</td>\n",
       "      <td>1148</td>\n",
       "      <td>6578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>75</td>\n",
       "      <td>1156</td>\n",
       "      <td>8270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>97</td>\n",
       "      <td>1126</td>\n",
       "      <td>2899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Report_id  Asset_id_vehicle  Asset_id_home  Claim_id\n",
       "0         26                82           1132      6578\n",
       "1          8                24           1141      8270\n",
       "2         13                89           1148      6578\n",
       "3         11                75           1156      8270\n",
       "4         10                97           1126      2899"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Reports_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT INTO Report VALUES (26,82,1132,6578);\n",
      "INSERT INTO Report VALUES (8,24,1141,8270);\n",
      "INSERT INTO Report VALUES (13,89,1148,6578);\n",
      "INSERT INTO Report VALUES (11,75,1156,8270);\n",
      "INSERT INTO Report VALUES (10,97,1126,2899);\n",
      "INSERT INTO Report VALUES (13,58,1140,8513);\n",
      "INSERT INTO Report VALUES (1,63,1115,9838);\n",
      "INSERT INTO Report VALUES (30,68,1127,9226);\n",
      "INSERT INTO Report VALUES (20,42,1153,2585);\n",
      "INSERT INTO Report VALUES (11,4,1132,6191);\n",
      "INSERT INTO Report VALUES (15,32,1129,4005);\n",
      "INSERT INTO Report VALUES (22,90,1125,9838);\n",
      "INSERT INTO Report VALUES (12,41,1126,6051);\n",
      "INSERT INTO Report VALUES (20,92,1160,7396);\n",
      "INSERT INTO Report VALUES (24,42,1113,2267);\n",
      "INSERT INTO Report VALUES (7,61,1113,6311);\n",
      "INSERT INTO Report VALUES (29,2,1136,8099);\n",
      "INSERT INTO Report VALUES (27,28,1141,3558);\n",
      "INSERT INTO Report VALUES (1,29,1137,9792);\n",
      "INSERT INTO Report VALUES (18,59,1145,9226);\n",
      "INSERT INTO Report VALUES (26,76,1118,9792);\n",
      "INSERT INTO Report VALUES (11,83,1148,4152);\n",
      "INSERT INTO Report VALUES (28,48,1143,3747);\n",
      "INSERT INTO Report VALUES (14,92,1150,8734);\n",
      "INSERT INTO Report VALUES (27,71,1158,4556);\n",
      "INSERT INTO Report VALUES (22,45,1118,9433);\n",
      "INSERT INTO Report VALUES (12,64,1157,6390);\n",
      "INSERT INTO Report VALUES (4,16,1129,8041);\n",
      "INSERT INTO Report VALUES (5,17,1134,4385);\n",
      "INSERT INTO Report VALUES (9,76,1127,3558);\n"
     ]
    }
   ],
   "source": [
    "#creating INSERT SQL file for Transactions table\n",
    "for Report_id, Asset_id_vehicle, Asset_id_home, Claim_id  in Reports_data.values.tolist():\n",
    "    print(\"INSERT INTO Report VALUES ({},{},{},{});\".format(Report_id, Asset_id_vehicle, Asset_id_home, Claim_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
